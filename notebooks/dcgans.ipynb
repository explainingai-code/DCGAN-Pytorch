{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from PIL import Image\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    r\"\"\"\n",
    "    Nothing special here. Just a simple dataset class for mnist images.\n",
    "    Created a dataset class rather using torchvision to allow\n",
    "    replacement with any other image dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, split, im_path, im_ext='png'):\n",
    "        r\"\"\"\n",
    "        Init method for initializing the dataset properties\n",
    "        :param split: train/test to locate the image files\n",
    "        :param im_path: root folder of images\n",
    "        :param im_ext: image extension. assumes all\n",
    "        images would be this type.\n",
    "        \"\"\"\n",
    "        self.split = split\n",
    "        self.im_ext = im_ext\n",
    "        self.images, self.labels = self.load_images(im_path)\n",
    "    \n",
    "    def load_images(self, im_path):\n",
    "        r\"\"\"\n",
    "        Gets all images from the path specified\n",
    "        and stacks them all up\n",
    "        :param im_path:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert os.path.exists(im_path), \"images path {} does not exist\".format(im_path)\n",
    "        ims = []\n",
    "        labels = []\n",
    "        for d_name in tqdm(os.listdir(im_path)):\n",
    "            for fname in glob.glob(os.path.join(im_path, d_name, '*.{}'.format(self.im_ext))):\n",
    "                ims.append(fname)\n",
    "                labels.append(int(d_name))\n",
    "        print('Found {} images for split {}'.format(len(ims), self.split))\n",
    "        return ims, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        im = Image.open(self.images[index])\n",
    "        im_tensor = torchvision.transforms.ToTensor()(im)\n",
    "        im.close()\n",
    "        \n",
    "        # Uncomment below 4 lines for colored mnist images\n",
    "        # a = (im_tensor[0]*random.uniform(0.2, 1.0)).unsqueeze(0)\n",
    "        # b = (im_tensor[0]*random.uniform(0.2, 1.0)).unsqueeze(0)\n",
    "        # c = (im_tensor[0]*random.uniform(0.2, 1.0)).unsqueeze(0)\n",
    "        # im_tensor = torch.cat([a, b, c], dim=0)\n",
    "        \n",
    "        # Convert input to -1 to 1 range.\n",
    "        im_tensor = (2 * im_tensor) - 1\n",
    "        return im_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MnistDataset('train', '../data/train/images')\n",
    "mnist_loader_train = DataLoader(mnist_train, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_test = MnistDataset('test', '../data/test/images')\n",
    "mnist_loader_test = DataLoader(mnist_test, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "'''\n",
    "Source code from \n",
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html \n",
    "and \n",
    "https://arxiv.org/pdf/1511.06434.pdf\n",
    "\n",
    "'''\n",
    "latent_dim = 100\n",
    "in_channels = [512, 256, 128, 64]\n",
    "kernel_size = [4,4,4,4,4]\n",
    "stride = [1,2,2,2,2]\n",
    "padding = [0,1,1,1,1]\n",
    "out_channels = 3\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,latent_dim = latent_dim, in_channels = in_channels, kernel_size = kernel_size, stride = stride, padding = padding, out_channels = out_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            ###\n",
    "            nn.ConvTranspose2d(self.latent_dim,self.in_channels[0],self.kernel_size[0], self.stride[0], self.padding[0], bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels[0]),\n",
    "            nn.ReLU(True),\n",
    "            ###\n",
    "            nn.ConvTranspose2d(self.in_channels[0],self.in_channels[1],self.kernel_size[1], self.stride[1], self.padding[1], bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels[1]),\n",
    "            nn.ReLU(True),\n",
    "            ###\n",
    "            nn.ConvTranspose2d(self.in_channels[1],self.in_channels[2],self.kernel_size[2], self.stride[2], self.padding[2], bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels[2]),\n",
    "            nn.ReLU(True),\n",
    "            ###\n",
    "            nn.ConvTranspose2d(self.in_channels[2],self.in_channels[3],self.kernel_size[3], self.stride[3], self.padding[3], bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels[3]),\n",
    "            nn.ReLU(True),\n",
    "            ###\n",
    "            nn.ConvTranspose2d(self.in_channels[3],self.out_channels,self.kernel_size[4], self.stride[4], self.padding[4], bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels = in_channels, kernel_size = kernel_size, stride = stride, padding = padding, out_channels = out_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_channels = np.flip(in_channels)\n",
    "        self.kernel_size = np.flip(kernel_size)\n",
    "        self.stride = np.flip(stride)\n",
    "        self.padding = np.flip(padding)\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            ###\n",
    "            nn.Conv2d(self.out_channels,self.in_channels[0],self.kernel_size[0], self.stride[0], self.padding[0], bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ###\n",
    "            nn.Conv2d(self.in_channels[0],self.in_channels[1],self.kernel_size[1], self.stride[1], self.padding[1], bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ###\n",
    "            nn.Conv2d(self.in_channels[1],self.in_channels[2],self.kernel_size[2], self.stride[2], self.padding[2], bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels[2]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ###\n",
    "            nn.Conv2d(self.in_channels[2],self.in_channels[3],self.kernel_size[3], self.stride[3], self.padding[3], bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels[3]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ###\n",
    "            nn.Conv2d(self.in_channels[3],1,self.kernel_size[4], self.stride[4], self.padding[4], bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
